{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a962959",
   "metadata": {},
   "source": [
    "# DAEN 429 Final Project\n",
    "Sydney Flake, Maddie Bird, Jade Winebright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3ce65",
   "metadata": {},
   "source": [
    "## Phase 0: Setup + ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c049e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use GPU if available\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 429\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Turn on cuDNN benchmark for speed (optional)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f121953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00fcb963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 87000\n",
      "Number of classes: 29\n",
      "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'] ...\n"
     ]
    }
   ],
   "source": [
    "# Load the full ASL dataset\n",
    "\n",
    "DATA_ROOT = \"/Users/flake/Documents/DAEN429/project/Datasets/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=DATA_ROOT, transform=None)\n",
    "print(\"Total images:\", len(full_dataset))\n",
    "print(\"Number of classes:\", len(full_dataset.classes))\n",
    "print(\"Classes:\", full_dataset.classes[:10], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3682f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (indices): 69600\n",
      "Val size (indices): 17400\n"
     ]
    }
   ],
   "source": [
    "# ---- Stratified 80/20 split with seed = 429 ----\n",
    "indices = np.arange(len(full_dataset))\n",
    "labels = np.array(full_dataset.targets)  # class indices 0..(num_classes-1)\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=429\n",
    ")\n",
    "\n",
    "print(\"Train size (indices):\", len(train_idx))\n",
    "print(\"Val size (indices):\", len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123ea263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for training and validation sets\n",
    "\n",
    "# ImageNet normalization (what ResNet-18 expects)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 69600\n",
      "Val size: 17400\n"
     ]
    }
   ],
   "source": [
    "# Custom Subset class to apply different transforms per split\n",
    "\n",
    "\"\"\"# ---- Subset wrapper that allows per-split transforms ----\n",
    "class SubsetWithTransform(Subset):\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        super().__init__(dataset, indices)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        img, label = self.dataset[real_idx]  # base dataset has transform=None\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Make sure base dataset doesn’t apply transforms itself\n",
    "full_dataset.transform = None\n",
    "\n",
    "train_dataset = SubsetWithTransform(full_dataset, train_idx, transform=train_transform)\n",
    "val_dataset   = SubsetWithTransform(full_dataset, val_idx,   transform=val_transform)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Val size:\", len(val_dataset))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b735c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train size: 69600\n",
      "Final val size: 17400\n",
      "Train sample type: <class 'torch.Tensor'>\n",
      "Train sample shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create base dataset each with its own transforms\n",
    "# Dataset for training: same files, but with train_transform\n",
    "train_full = datasets.ImageFolder(root=DATA_ROOT, transform=train_transform)\n",
    "\n",
    "# Dataset for validation: same files, but with val_transform\n",
    "val_full   = datasets.ImageFolder(root=DATA_ROOT, transform=val_transform)\n",
    "\n",
    "# Now apply the *same indices* to each\n",
    "train_dataset = Subset(train_full, train_idx)\n",
    "val_dataset   = Subset(val_full,   val_idx)\n",
    "\n",
    "print(\"Final train size:\", len(train_dataset))\n",
    "print(\"Final val size:\", len(val_dataset))\n",
    "\n",
    "# Sanity check: the first sample should be a tensor\n",
    "x0, y0 = train_dataset[0]\n",
    "print(\"Train sample type:\", type(x0))     # should be <class 'torch.Tensor'>\n",
    "print(\"Train sample shape:\", x0.shape)    # e.g. torch.Size([3, 224, 224])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9198e060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train batches: 1088\n",
      "Num val batches: 272\n"
     ]
    }
   ],
   "source": [
    "# ---- DataLoaders ----\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "pin = True if device.type == \"cuda\" else False\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=pin,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=pin,\n",
    ")\n",
    "\n",
    "print(\"Num train batches:\", len(train_loader))\n",
    "print(\"Num val batches:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118b64f",
   "metadata": {},
   "source": [
    "## Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd4b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 29\n",
      "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Classes:\", full_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0182548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet18_model(num_classes, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create a ResNet-18 model with a custom classifier head for ASL classes.\n",
    "    If pretrained=True → use ImageNet weights (for T-A, T-B, T-C).\n",
    "    If pretrained=False → random init (for S-A).\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = resnet18(weights=weights)\n",
    "        print(\"Loaded ResNet-18 with ImageNet pretrained weights.\")\n",
    "    else:\n",
    "        model = resnet18(weights=None)\n",
    "        print(\"Loaded ResNet-18 from scratch (no pretrained weights).\")\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f675676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing/unfreezing policies\n",
    "def apply_freezing_policy(model, policy):\n",
    "    \"\"\"\n",
    "    policy: one of {\"T-A\", \"T-B\", \"T-C\", \"S-A\"}\n",
    "    \n",
    "    T-A: Head-only, freeze all backbone, train fc.\n",
    "    T-B: Freeze stem + layer1 + layer2 + layer3; train layer4 + fc.\n",
    "    T-C: Freeze stem + layer1 + layer2; train layer3 + layer4 + fc.\n",
    "    S-A: From scratch, train all layers (no freezing).\n",
    "    \"\"\"\n",
    "    # First, freeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if policy == \"T-A\":\n",
    "        # Train only the classifier head\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif policy == \"T-B\":\n",
    "        # Train layer4 and head\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif policy == \"T-C\":\n",
    "        # Train layer3, layer4, and head\n",
    "        for param in model.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif policy == \"S-A\":\n",
    "        # From scratch: train everything\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown policy: {policy}\")\n",
    "\n",
    "    # Optional: set BatchNorm layers in frozen parts to eval mode\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            # if all params in this BN are frozen, keep it in eval\n",
    "            if not any(p.requires_grad for p in m.parameters()):\n",
    "                m.eval()\n",
    "\n",
    "    # Print a quick summary\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Policy {policy}: trainable params = {trainable_params}/{total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0cda1",
   "metadata": {},
   "source": [
    "Reusable code for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384c8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer(model, lr=1e-3, weight_decay=1e-4, optimizer_name=\"Adam\"):\n",
    "    \"\"\"\n",
    "    Returns an optimizer over ONLY trainable parameters.\n",
    "    \"\"\"\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    \n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32f2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_targets.append(labels.detach().cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
    "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6d7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.append(preds.detach().cpu())\n",
    "            all_targets.append(labels.detach().cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
    "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1, all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9940d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"exp\"\n",
    "):\n",
    "    optimizer = get_optimizer(model, lr=lr, weight_decay=weight_decay, optimizer_name=optimizer_name)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_state = {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"val_f1\": val_f1,\n",
    "                \"val_acc\": val_acc,\n",
    "            }\n",
    "\n",
    "        print(\n",
    "            f\"[{experiment_name}] Epoch {epoch:02d}/{num_epochs:02d} | \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[{experiment_name}] Best val macro-F1: {best_val_f1:.4f}\")\n",
    "    return model, history, best_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec448c2",
   "metadata": {},
   "source": [
    "### T-A: Head Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ca51348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ResNet-18 with ImageNet pretrained weights.\n",
      "Policy T-A: trainable params = 14877/11191389\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m apply_freezing_policy(model_TA, policy=\u001b[33m\"\u001b[39m\u001b[33mT-A\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m model_TA = model_TA.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model_TA, history_TA, best_TA = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_TA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# you can adjust\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAdam\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mT-A_head_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, device, num_epochs, lr, weight_decay, optimizer_name, experiment_name)\u001b[39m\n\u001b[32m     24\u001b[39m best_state = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     train_loss, train_acc, train_f1 = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, device)\n\u001b[32m     30\u001b[39m     history[\u001b[33m\"\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m\"\u001b[39m].append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, device)\u001b[39m\n\u001b[32m     10\u001b[39m labels = labels.to(device)\n\u001b[32m     12\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m     15\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[39m, in \u001b[36mResNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torchvision/models/resnet.py:276\u001b[39m, in \u001b[36mResNet._forward_impl\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    274\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer2(x)\n\u001b[32m    275\u001b[39m x = \u001b[38;5;28mself\u001b[39m.layer3(x)\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m x = \u001b[38;5;28mself\u001b[39m.avgpool(x)\n\u001b[32m    279\u001b[39m x = torch.flatten(x, \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torchvision/models/resnet.py:96\u001b[39m, in \u001b[36mBasicBlock.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     93\u001b[39m out = \u001b[38;5;28mself\u001b[39m.bn1(out)\n\u001b[32m     94\u001b[39m out = \u001b[38;5;28mself\u001b[39m.relu(out)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m out = \u001b[38;5;28mself\u001b[39m.bn2(out)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.downsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/daen429/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m'\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(F.pad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode),\n\u001b[32m    454\u001b[39m                     weight, bias, \u001b[38;5;28mself\u001b[39m.stride,\n\u001b[32m    455\u001b[39m                     _pair(\u001b[32m0\u001b[39m), \u001b[38;5;28mself\u001b[39m.dilation, \u001b[38;5;28mself\u001b[39m.groups)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===== T-A: Head-only finetuning =====\n",
    "model_TA = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
    "apply_freezing_policy(model_TA, policy=\"T-A\")\n",
    "model_TA = model_TA.to(device)\n",
    "\n",
    "model_TA, history_TA, best_TA = train_model(\n",
    "    model_TA,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,          # you can adjust\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"T-A_head_only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32330d76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_TA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mcheckpoints\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m ta_ckpt_path = \u001b[33m\"\u001b[39m\u001b[33m/checkpoints/resnet18_TA_best.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m torch.save(\u001b[43mbest_TA\u001b[49m, ta_ckpt_path)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaved best T-A checkpoint to:\u001b[39m\u001b[33m\"\u001b[39m, ta_ckpt_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'best_TA' is not defined"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "ta_ckpt_path = \"/checkpoints/resnet18_TA_best.pth\"\n",
    "torch.save(best_TA, ta_ckpt_path)\n",
    "print(\"Saved best T-A checkpoint to:\", ta_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ec155",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 5) Save the best T-A checkpoint\n",
    "os.makedirs(\"/content/drive/MyDrive/DAEN429/checkpoints\", exist_ok=True)\n",
    "\n",
    "ta_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TA_best.pth\"\n",
    "torch.save(best_TA, ta_ckpt_path)\n",
    "print(\"Saved best T-A checkpoint to:\", ta_ckpt_path)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07873237",
   "metadata": {},
   "source": [
    "### T-B: Last Block Unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954de024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== T-B: Last block (layer4) + head finetuning =====\n",
    "\n",
    "model_TB = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
    "apply_freezing_policy(model_TB, policy=\"T-B\")\n",
    "model_TB = model_TB.to(device)\n",
    "\n",
    "model_TB, history_TB, best_TB = train_model(\n",
    "    model_TB,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,          # adjust if you want longer/shorter\n",
    "    lr=1e-4,                # often a bit smaller when unfreezing more layers\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"T-B_last_block_plus_head\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c890dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "tb_ckpt_path = \"/checkpoints/resnet18_TB_best.pth\"\n",
    "torch.save(best_TB, tb_ckpt_path)\n",
    "print(\"Saved best T-B checkpoint to:\", tb_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Save the best T-B model checkpoint\n",
    "tb_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TB_best.pth\"\n",
    "torch.save(best_TB, tb_ckpt_path)\n",
    "print(\"Saved best T-B checkpoint to:\", tb_ckpt_path)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393e559",
   "metadata": {},
   "source": [
    "### T-C: Progressive Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== T-C: Progressive unfreezing =====\n",
    "\n",
    "# 1) Recreate same model architecture used in T-B\n",
    "model_TC = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
    "\n",
    "# 2) Load best T-B checkpoint\n",
    "tb_checkpoint = torch.load(\"checkpoints/resnet18_TB_best.pth\", map_location=device)\n",
    "model_TC.load_state_dict(tb_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "print(\n",
    "    f\"Loaded T-B checkpoint from epoch {tb_checkpoint['epoch']} \"\n",
    "    f\"with val F1 = {tb_checkpoint['val_f1']:.4f}\"\n",
    ")\n",
    "\n",
    "# 3) Apply T-C freezing policy (layer3 + layer4 + fc trainable)\n",
    "apply_freezing_policy(model_TC, policy=\"T-C\")\n",
    "\n",
    "# 4) Move to GPU/CPU\n",
    "model_TC = model_TC.to(device)\n",
    "\n",
    "# 5) Train with a lower LR (to avoid destroying T-B’s good weights)\n",
    "model_TC, history_TC, best_TC = train_model(\n",
    "    model_TC,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,                # adjust as needed\n",
    "    lr=5e-5,                      # smaller LR recommended\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"T-C_progressive_unfreeze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "tc_ckpt_path = \"/checkpoints/resnet18_TC_best.pth\"\n",
    "torch.save(best_TC, tc_ckpt_path)\n",
    "print(\"Saved best T-C checkpoint to:\", tc_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a73331",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 6) Save best checkpoint\n",
    "tc_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TC_best.pth\"\n",
    "torch.save(best_TC, tc_ckpt_path)\n",
    "print(\"Saved best T-C checkpoint to:\", tc_ckpt_path)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbcd277",
   "metadata": {},
   "source": [
    "### S-A: Train From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710094b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daen429)",
   "language": "python",
   "name": "daen429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
