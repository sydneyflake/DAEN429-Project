{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a962959",
   "metadata": {},
   "source": [
    "# DAEN 429 Final Project\n",
    "Sydney Flake, Maddie Bird, Jade Winebright"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3ce65",
   "metadata": {},
   "source": [
    "## Phase 0: Setup + ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use GPU if available\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# For reproducibility\n",
    "SEED = 429\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Turn on cuDNN benchmark for speed (optional)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f121953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "#path = kagglehub.dataset_download(\"grassknoted/asl-alphabet\")\n",
    "\n",
    "#print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00fcb963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 87000\n",
      "Number of classes: 29\n",
      "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'] ...\n"
     ]
    }
   ],
   "source": [
    "# Load the full ASL dataset\n",
    "\n",
    "DATA_ROOT = \"/Users/flake/Documents/DAEN429/project/Datasets/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=DATA_ROOT, transform=None)\n",
    "print(\"Total images:\", len(full_dataset))\n",
    "print(\"Number of classes:\", len(full_dataset.classes))\n",
    "print(\"Classes:\", full_dataset.classes[:10], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a3682f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (indices): 69600\n",
      "Val size (indices): 17400\n"
     ]
    }
   ],
   "source": [
    "# ---- Stratified 80/20 split with seed = 429 ----\n",
    "indices = np.arange(len(full_dataset))\n",
    "labels = np.array(full_dataset.targets)  # class indices 0..(num_classes-1)\n",
    "\n",
    "train_idx, val_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    stratify=labels,\n",
    "    random_state=429\n",
    ")\n",
    "\n",
    "print(\"Train size (indices):\", len(train_idx))\n",
    "print(\"Val size (indices):\", len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "123ea263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations for training and validation sets\n",
    "\n",
    "# ImageNet normalization (what ResNet-18 expects)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c8cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 69600\n",
      "Val size: 17400\n"
     ]
    }
   ],
   "source": [
    "# Custom Subset class to apply different transforms per split\n",
    "\n",
    "\"\"\"# ---- Subset wrapper that allows per-split transforms ----\n",
    "class SubsetWithTransform(Subset):\n",
    "    def __init__(self, dataset, indices, transform=None):\n",
    "        super().__init__(dataset, indices)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        img, label = self.dataset[real_idx]  # base dataset has transform=None\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Make sure base dataset doesn’t apply transforms itself\n",
    "full_dataset.transform = None\n",
    "\n",
    "train_dataset = SubsetWithTransform(full_dataset, train_idx, transform=train_transform)\n",
    "val_dataset   = SubsetWithTransform(full_dataset, val_idx,   transform=val_transform)\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Val size:\", len(val_dataset))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b735c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train size: 69600\n",
      "Final val size: 17400\n",
      "Train sample type: <class 'torch.Tensor'>\n",
      "Train sample shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Create base dataset each with its own transforms\n",
    "# Dataset for training: same files, but with train_transform\n",
    "train_full = datasets.ImageFolder(root=DATA_ROOT, transform=train_transform)\n",
    "\n",
    "# Dataset for validation: same files, but with val_transform\n",
    "val_full   = datasets.ImageFolder(root=DATA_ROOT, transform=val_transform)\n",
    "\n",
    "# Now apply the *same indices* to each\n",
    "train_dataset = Subset(train_full, train_idx)\n",
    "val_dataset   = Subset(val_full,   val_idx)\n",
    "\n",
    "print(\"Final train size:\", len(train_dataset))\n",
    "print(\"Final val size:\", len(val_dataset))\n",
    "\n",
    "# Sanity check: the first sample should be a tensor\n",
    "x0, y0 = train_dataset[0]\n",
    "print(\"Train sample type:\", type(x0))     # should be <class 'torch.Tensor'>\n",
    "print(\"Train sample shape:\", x0.shape)    # e.g. torch.Size([3, 224, 224])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9198e060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num train batches: 1088\n",
      "Num val batches: 272\n"
     ]
    }
   ],
   "source": [
    "# ---- DataLoaders ----\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "pin = True if device.type == \"cuda\" else False\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=pin,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=pin,\n",
    ")\n",
    "\n",
    "print(\"Num train batches:\", len(train_loader))\n",
    "print(\"Num val batches:\", len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118b64f",
   "metadata": {},
   "source": [
    "## Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddd4b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 29\n",
      "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "print(\"Classes:\", full_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0182548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet18_model(num_classes, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create a ResNet-18 model with a custom classifier head for ASL classes.\n",
    "    If pretrained=True → use ImageNet weights (for T-A, T-B, T-C).\n",
    "    If pretrained=False → random init (for S-A).\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1\n",
    "        model = resnet18(weights=weights)\n",
    "        print(\"Loaded ResNet-18 with ImageNet pretrained weights.\")\n",
    "    else:\n",
    "        model = resnet18(weights=None)\n",
    "        print(\"Loaded ResNet-18 from scratch (no pretrained weights).\")\n",
    "    \n",
    "    # Replace the final fully connected layer\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f675676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing/unfreezing policies\n",
    "def apply_freezing_policy(model, policy):\n",
    "    \"\"\"\n",
    "    policy: one of {\"T-A\", \"T-B\", \"T-C\", \"S-A\"}\n",
    "    \n",
    "    T-A: Head-only, freeze all backbone, train fc.\n",
    "    T-B: Freeze stem + layer1 + layer2 + layer3; train layer4 + fc.\n",
    "    T-C: Freeze stem + layer1 + layer2; train layer3 + layer4 + fc.\n",
    "    S-A: From scratch, train all layers (no freezing).\n",
    "    \"\"\"\n",
    "    # First, freeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if policy == \"T-A\":\n",
    "        # Train only the classifier head\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif policy == \"T-B\":\n",
    "        # Train layer4 and head\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif policy == \"T-C\":\n",
    "        # Train layer3, layer4, and head\n",
    "        for param in model.layer3.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif policy == \"S-A\":\n",
    "        # From scratch: train everything\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown policy: {policy}\")\n",
    "\n",
    "    # Optional: set BatchNorm layers in frozen parts to eval mode\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            # if all params in this BN are frozen, keep it in eval\n",
    "            if not any(p.requires_grad for p in m.parameters()):\n",
    "                m.eval()\n",
    "\n",
    "    # Print a quick summary\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Policy {policy}: trainable params = {trainable_params}/{total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0cda1",
   "metadata": {},
   "source": [
    "Reusable code for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "384c8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def get_optimizer(model, lr=1e-3, weight_decay=1e-4, optimizer_name=\"Adam\"):\n",
    "    \"\"\"\n",
    "    Returns an optimizer over ONLY trainable parameters.\n",
    "    \"\"\"\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    if optimizer_name == \"Adam\":\n",
    "        optimizer = optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_name == \"SGD\":\n",
    "        optimizer = optim.SGD(params, lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer_name}\")\n",
    "    \n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32f2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.append(preds.detach().cpu())\n",
    "        all_targets.append(labels.detach().cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
    "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6d7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.append(preds.detach().cpu())\n",
    "            all_targets.append(labels.detach().cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = accuracy_score(all_targets, all_preds)\n",
    "    epoch_f1 = f1_score(all_targets, all_preds, average=\"macro\")\n",
    "\n",
    "    return epoch_loss, epoch_acc, epoch_f1, all_preds, all_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9940d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"exp\"\n",
    "):\n",
    "    optimizer = get_optimizer(model, lr=lr, weight_decay=weight_decay, optimizer_name=optimizer_name)\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "\n",
    "    best_val_f1 = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, device)\n",
    "        val_loss, val_acc, val_f1, _, _ = evaluate(model, val_loader, device)\n",
    "\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_state = {\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"val_f1\": val_f1,\n",
    "                \"val_acc\": val_acc,\n",
    "            }\n",
    "\n",
    "        print(\n",
    "            f\"[{experiment_name}] Epoch {epoch:02d}/{num_epochs:02d} | \"\n",
    "            f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(f\"\\n[{experiment_name}] Best val macro-F1: {best_val_f1:.4f}\")\n",
    "    return model, history, best_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec448c2",
   "metadata": {},
   "source": [
    "### T-A: Head Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca51348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== T-A: Head-only finetuning =====\n",
    "model_TA = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
    "apply_freezing_policy(model_TA, policy=\"T-A\")\n",
    "model_TA = model_TA.to(device)\n",
    "\n",
    "model_TA, history_TA, best_TA = train_model(\n",
    "    model_TA,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,          # you can adjust\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"T-A_head_only\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32330d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For personal storage\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "ta_ckpt_path = \"/checkpoints/resnet18_TA_best.pth\"\n",
    "torch.save(best_TA, ta_ckpt_path)\n",
    "print(\"Saved best T-A checkpoint to:\", ta_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40ec155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Drive storage\n",
    "\"\"\"# 5) Save the best T-A checkpoint\n",
    "os.makedirs(\"/content/drive/MyDrive/DAEN429/checkpoints\", exist_ok=True)\n",
    "\n",
    "ta_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TA_best.pth\"\n",
    "torch.save(best_TA, ta_ckpt_path)\n",
    "print(\"Saved best T-A checkpoint to:\", ta_ckpt_path)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07873237",
   "metadata": {},
   "source": [
    "### T-B: Last Block Unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954de024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== T-B: Last block (layer4) + head finetuning =====\n",
    "\n",
    "model_TB = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
    "apply_freezing_policy(model_TB, policy=\"T-B\")\n",
    "model_TB = model_TB.to(device)\n",
    "\n",
    "model_TB, history_TB, best_TB = train_model(\n",
    "    model_TB,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,          # adjust if you want longer/shorter\n",
    "    lr=1e-4,                # often a bit smaller when unfreezing more layers\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"T-B_last_block_plus_head\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c890dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For personal storage\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "tb_ckpt_path = \"/checkpoints/resnet18_TB_best.pth\"\n",
    "torch.save(best_TB, tb_ckpt_path)\n",
    "print(\"Saved best T-B checkpoint to:\", tb_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Drive storage\n",
    "\"\"\"# Save the best T-B model checkpoint\n",
    "tb_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TB_best.pth\"\n",
    "torch.save(best_TB, tb_ckpt_path)\n",
    "print(\"Saved best T-B checkpoint to:\", tb_ckpt_path)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393e559",
   "metadata": {},
   "source": [
    "### T-C: Progressive Unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a3f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== T-C: Progressive unfreezing =====\n",
    "\n",
    "# 1) Recreate same model architecture used in T-B\n",
    "model_TC = create_resnet18_model(num_classes=num_classes, pretrained=True)\n",
    "\n",
    "# 2) Load best T-B checkpoint\n",
    "tb_checkpoint = torch.load(\"checkpoints/resnet18_TB_best.pth\", map_location=device)\n",
    "model_TC.load_state_dict(tb_checkpoint[\"model_state_dict\"])\n",
    "\n",
    "print(\n",
    "    f\"Loaded T-B checkpoint from epoch {tb_checkpoint['epoch']} \"\n",
    "    f\"with val F1 = {tb_checkpoint['val_f1']:.4f}\"\n",
    ")\n",
    "\n",
    "# 3) Apply T-C freezing policy (layer3 + layer4 + fc trainable)\n",
    "apply_freezing_policy(model_TC, policy=\"T-C\")\n",
    "\n",
    "# 4) Move to GPU/CPU\n",
    "model_TC = model_TC.to(device)\n",
    "\n",
    "# 5) Train with a lower LR (to avoid destroying T-B’s good weights)\n",
    "model_TC, history_TC, best_TC = train_model(\n",
    "    model_TC,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    device,\n",
    "    num_epochs=10,                # adjust as needed\n",
    "    lr=5e-5,                      # smaller LR recommended\n",
    "    weight_decay=1e-4,\n",
    "    optimizer_name=\"Adam\",\n",
    "    experiment_name=\"T-C_progressive_unfreeze\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For personal storage\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "tc_ckpt_path = \"/checkpoints/resnet18_TC_best.pth\"\n",
    "torch.save(best_TC, tc_ckpt_path)\n",
    "print(\"Saved best T-C checkpoint to:\", tc_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a73331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Drive storage\n",
    "\"\"\"# 6) Save best checkpoint\n",
    "tc_ckpt_path = \"/content/drive/MyDrive/DAEN429/checkpoints/resnet18_TC_best.pth\"\n",
    "torch.save(best_TC, tc_ckpt_path)\n",
    "print(\"Saved best T-C checkpoint to:\", tc_ckpt_path)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbcd277",
   "metadata": {},
   "source": [
    "### S-A: Train From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710094b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (daen429)",
   "language": "python",
   "name": "daen429"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
